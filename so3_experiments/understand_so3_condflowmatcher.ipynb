{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from einops import rearrange\n",
    "from functorch import vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial rotation matrices x0: tensor([[[-1.6438, -0.2921,  0.8579],\n",
      "         [-0.5794,  0.5201, -1.2595],\n",
      "         [ 0.2056, -0.1793, -0.7726]],\n",
      "\n",
      "        [[ 1.6532,  0.4226,  0.7754],\n",
      "         [-1.5206,  1.0661, -1.9345],\n",
      "         [-0.2122, -0.2998, -0.7949]]], requires_grad=True)\n",
      "Shape of x0: torch.Size([2, 3, 3])\n",
      "Initial rotation matrices x1: tensor([[[-0.7484,  0.4143, -0.0590],\n",
      "         [ 0.6639,  0.7768, -0.1967],\n",
      "         [-1.6091,  0.3850, -0.5262]],\n",
      "\n",
      "        [[ 0.7747,  0.3806, -1.4528],\n",
      "         [-0.7646,  0.9479,  0.5471],\n",
      "         [-0.8111, -0.6761,  0.3001]]], requires_grad=True)\n",
      "Shape of x1: torch.Size([2, 3, 3])\n",
      "Time values t: tensor([0.8670, 0.8481], requires_grad=True)\n",
      "Shape of t: torch.Size([2])\n",
      "Flattened x0: tensor([[-1.6438, -0.2921,  0.8579, -0.5794,  0.5201, -1.2595,  0.2056, -0.1793,\n",
      "         -0.7726],\n",
      "        [ 1.6532,  0.4226,  0.7754, -1.5206,  1.0661, -1.9345, -0.2122, -0.2998,\n",
      "         -0.7949]], grad_fn=<ViewBackward0>)\n",
      "Shape of flattened x0: torch.Size([2, 9])\n",
      "Flattened x1: tensor([[-0.6489,  0.3592, -0.0512,  0.5756,  0.6735, -0.1706, -1.3951,  0.3338,\n",
      "         -0.4562],\n",
      "        [ 0.6570,  0.3228, -1.2321, -0.6484,  0.8039,  0.4640, -0.6879, -0.5734,\n",
      "          0.2545]], grad_fn=<ViewBackward0>)\n",
      "Shape of flattened x1: torch.Size([2, 9])\n",
      "Identity matrix for vmap: tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 1.]]])\n",
      "Shape of identity matrix: torch.Size([2, 9, 9])\n",
      "Raw derivatives x1_dot: tensor([[-0.7484,  0.7747],\n",
      "        [ 0.4143,  0.3806],\n",
      "        [-0.0590, -1.4528],\n",
      "        [ 0.6639, -0.7646],\n",
      "        [ 0.7768,  0.9479],\n",
      "        [-0.1967,  0.5471],\n",
      "        [-1.6091, -0.8111],\n",
      "        [ 0.3850, -0.6761],\n",
      "        [-0.5262,  0.3001]], grad_fn=<SliceBackwardBackward0>)\n",
      "Shape of raw derivatives x1_dot: torch.Size([9, 2])\n",
      "Reshaped derivatives x1_dot: tensor([[[-0.7484,  0.4143, -0.0590],\n",
      "         [ 0.6639,  0.7768, -0.1967],\n",
      "         [-1.6091,  0.3850, -0.5262]],\n",
      "\n",
      "        [[ 0.7747,  0.3806, -1.4528],\n",
      "         [-0.7646,  0.9479,  0.5471],\n",
      "         [-0.8111, -0.6761,  0.3001]]], grad_fn=<PermuteBackward0>)\n",
      "Shape of reshaped x1_dot: torch.Size([2, 3, 3])\n",
      "Flow derivative computed for batch: tensor([[[-0.7484,  0.4143, -0.0590],\n",
      "         [ 0.6639,  0.7768, -0.1967],\n",
      "         [-1.6091,  0.3850, -0.5262]],\n",
      "\n",
      "        [[ 0.7747,  0.3806, -1.4528],\n",
      "         [-0.7646,  0.9479,  0.5471],\n",
      "         [-0.8111, -0.6761,  0.3001]]], grad_fn=<PermuteBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228692/2902184808.py:43: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  x1_dot = vmap(index_time_derivative, in_dims=1)(identity_matrix)\n"
     ]
    }
   ],
   "source": [
    "# Example inputs to simulate functionality\n",
    "def generate_example_inputs(batch_size):\n",
    "    # Generate random SO(3) rotation matrices\n",
    "    x0 = torch.randn(batch_size, 3, 3, requires_grad=True)  # Simulated input (not guaranteed to be SO(3))\n",
    "    x1 = torch.randn(batch_size, 3, 3, requires_grad=True)\n",
    "    t = torch.rand(batch_size, requires_grad=True)  # Random time values\n",
    "    return x0, x1, t\n",
    "\n",
    "# The demonstration function for compute_conditional_flow_simple\n",
    "def demo_compute_conditional_flow_simple(batch_size):\n",
    "    # Step 1: Generate example inputs\n",
    "    x0, x1, t = generate_example_inputs(batch_size)\n",
    "    print(\"Initial rotation matrices x0:\", x0)\n",
    "    print(\"Shape of x0:\", x0.shape)\n",
    "    print(\"Initial rotation matrices x1:\", x1)\n",
    "    print(\"Shape of x1:\", x1.shape)\n",
    "    print(\"Time values t:\", t)\n",
    "    print(\"Shape of t:\", t.shape)\n",
    "\n",
    "    # Step 2: Flatten rotation matrices\n",
    "    x0_flat = rearrange(x0, \"b c d -> b (c d)\", c=3, d=3)\n",
    "    x1_flat = rearrange(x1 * t[:, None, None], \"b c d -> b (c d)\", c=3, d=3)  # Include t in computation\n",
    "    print(\"Flattened x0:\", x0_flat)\n",
    "    print(\"Shape of flattened x0:\", x0_flat.shape)\n",
    "    print(\"Flattened x1:\", x1_flat)\n",
    "    print(\"Shape of flattened x1:\", x1_flat.shape)\n",
    "\n",
    "    # Step 3: Define the derivative computation helper function\n",
    "    def index_time_derivative(i):\n",
    "        return torch.autograd.grad(\n",
    "            outputs=x1_flat,\n",
    "            inputs=t,\n",
    "            grad_outputs=i,\n",
    "            create_graph=True,\n",
    "            retain_graph=True\n",
    "        )[0]\n",
    "\n",
    "    # Step 4: Use vmap to compute derivatives for each coordinate\n",
    "    identity_matrix = torch.eye(9).to(x0.device).repeat(batch_size, 1, 1)  # Identity per batch element\n",
    "    print(\"Identity matrix for vmap:\", identity_matrix)\n",
    "    print(\"Shape of identity matrix:\", identity_matrix.shape)\n",
    "\n",
    "    x1_dot = vmap(index_time_derivative, in_dims=1)(identity_matrix)\n",
    "    print(\"Raw derivatives x1_dot:\", x1_dot)\n",
    "    print(\"Shape of raw derivatives x1_dot:\", x1_dot.shape)\n",
    "\n",
    "    # Step 5: Reshape the result back into (batch, 3, 3) format\n",
    "    x1_dot = rearrange(x1_dot, \"(c d) b -> b c d\", c=3, d=3)\n",
    "    print(\"Reshaped derivatives x1_dot:\", x1_dot)\n",
    "    print(\"Shape of reshaped x1_dot:\", x1_dot.shape)\n",
    "\n",
    "    # Output the result\n",
    "    return x1_dot\n",
    "\n",
    "\n",
    "# Run the demonstration\n",
    "batch_size = 2  # Adjust batch size as needed\n",
    "output = demo_compute_conditional_flow_simple(batch_size)\n",
    "print(\"Flow derivative computed for batch:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foldflow-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
